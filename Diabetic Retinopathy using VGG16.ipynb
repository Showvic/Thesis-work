{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install split_folders","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import split_folders\n\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras import metrics\n\nfrom sklearn.utils import class_weight\nfrom collections import Counter\n\nimport matplotlib.pyplot as plt\n\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nprint(os.path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.makedirs('output')\nos.makedirs('output/train')\nos.makedirs('output/val')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.makedirs('output/test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_loc = '../input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/'\n\nsplit_folders.ratio(img_loc, output='output', seed=1, ratio=(0.1,0.8, 0.1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loc = 'output/train/'\nval_loc = 'output/val/'\ntest_loc = 'output/test/'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_loc= 'output/train'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trdata = ImageDataGenerator()\ntestdata = trdata.flow_from_directory(directory=train_loc, target_size=(224,224))\ntsdata = ImageDataGenerator()\ntraindata = tsdata.flow_from_directory(directory=val_loc, target_size=(224,224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vldata = ImageDataGenerator()\nvaldata = vldata.flow_from_directory(directory=test_loc, target_size=(224,224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg16 = VGG16(weights='imagenet')\nvgg16.summary()\n\nx  = vgg16.get_layer('fc2').output\nprediction = Dense(5, activation='softmax', name='predictions')(x)\n\nmodel = Model(inputs=vgg16.input, outputs=prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable = False\n\nfor layer in model.layers[-16:]:\n    layer.trainable = True\n    print(\"Layer '%s' is trainable\" % layer.name)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import SGD\n#opt = optimizers.sgd(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(optimizer='Adadelta', loss=categorical_crossentropy, \n              metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\"vgg16_diabetes.h5\", monitor='val_accuracy', verbose=1, \n                             save_best_only=True, save_weights_only=False, mode='auto')\nearly = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter = Counter(traindata.classes)                       \nmax_val = float(max(counter.values()))   \nclass_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit(traindata, steps_per_epoch=traindata.samples//traindata.batch_size, validation_data=valdata, \n                 class_weight=class_weights, validation_steps=valdata.samples//valdata.batch_size, \n                 epochs=100,callbacks=[checkpoint,early])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(hist.history['loss'], label='train')\nplt.plot(hist.history['val_loss'], label='val')\nplt.title('VGG16: Loss and Validation Loss (0.0001 = Adam LR)')\nplt.legend();\nplt.show()\n\nplt.plot(hist.history['accuracy'], label='train')\nplt.plot(hist.history['val_accuracy'], label='val')\nplt.title('VGG16: Accuracy and Validation Accuracy (0.0001 = Adam LR)')\nplt.legend();\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport itertools  \ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n#model = Model(inputs=vgg16.input, outputs=prediction)\n#model = Model(inputs=base_model.input, outputs= model(vgg16.output))\n#model = Model(input= base_model.input, output= model(base_model.output))\nY_pred = model.predict_generator(testdata)\ny_pred = np.argmax(Y_pred, axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(y_pred)):\n    print(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Compute confusion matrix\nfrom sklearn.metrics import classification_report, confusion_matrix\ntarget_names = ['No_DR','Mild','Moderate','Severe','Proliferate_DR']\ncnf_matrix = confusion_matrix(testdata.classes, y_pred)\nnp.set_printoptions(precision=2)\nprint(cnf_matrix.shape)\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=target_names,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=target_names, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential\n#from keras.models import Sequential #initialized the nural network#create cnn for 2d here image is 2d ,but video is 3d\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense #layer fully connected ann \n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_real = []\ny_pred =[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport cv2\nimport glob\nimport numpy as np\n\n\n\n\nfor filename in glob.glob('output//test//Mild//*.png'): #assuming gif\n    print(filename)\n    img=cv2.imread(filename)\n    #print(im)\n    #img = cv2.resize(img,(224,244))\n    img = np.reshape(img,[1,224,224,3])\n    classes = model.predict(img)\n    maxi = -1\n    for i in range(5):\n        if classes[0][i]> maxi :\n            index = i\n            maxi = classes[0][i]\n    y_real.append(0)\n    y_pred.append(index)\n    # convert the probabilities to class labels\n   \n# print the classification\n   \n\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for filename in glob.glob('output//test//Moderate//*.png'): #assuming gif\n    print(filename)\n    img=cv2.imread(filename)\n    #print(im)\n    #img = cv2.resize(img,(224,244))\n    img = np.reshape(img,[1,224,224,3])\n    classes = model.predict(img)\n    maxi = -1\n    for i in range(5):\n        if classes[0][i]> maxi :\n            index = i\n            maxi = classes[0][i]\n    y_real.append(1)\n    y_pred.append(index)\n    # convert the probabilities to class labels\n   \n# print the classification","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for filename in glob.glob('output//test//No_DR//*.png'): #assuming gif\n    print(filename)\n    img=cv2.imread(filename)\n    #print(im)\n    #img = cv2.resize(img,(224,244))\n    img = np.reshape(img,[1,224,224,3])\n    classes = model.predict(img)\n    maxi = -1\n    for i in range(5):\n        if classes[0][i]> maxi :\n            index = i\n            maxi = classes[0][i]\n    y_real.append(2)\n    y_pred.append(index)\n    # convert the probabilities to class labels\n   \n# print the classification","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for filename in glob.glob('output//test//Proliferate_DR//*.png'): #assuming gif\n    print(filename)\n    img=cv2.imread(filename)\n    #print(im)\n    #img = cv2.resize(img,(224,244))\n    img = np.reshape(img,[1,224,224,3])\n    classes = model.predict(img)\n    maxi = -1\n    for i in range(5):\n        if classes[0][i]> maxi :\n            index = i\n            maxi = classes[0][i]\n    y_real.append(3)\n    y_pred.append(index)\n    # convert the probabilities to class labels\n   \n# print the classification","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for filename in glob.glob('output//test//Severe//*.png'): #assuming gif\n    print(filename)\n    img=cv2.imread(filename)\n    #print(im)\n    #img = cv2.resize(img,(224,244))\n    img = np.reshape(img,[1,224,224,3])\n    classes = model.predict(img)\n    maxi = -1\n    for i in range(5):\n        if classes[0][i]> maxi :\n            index = i\n            maxi = classes[0][i]\n    y_real.append(4)\n    y_pred.append(index)\n    # convert the probabilities to class labels\n   \n# print the classification","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,precision_score\naccuracy = accuracy_score(y_real, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy*100)\nprint(y_real)\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#precesion.........\n\n\n# precision tp / (tp + fp)\nprecision = precision_score(y_real, y_pred,average='macro')\nprint('Precision: %f' % precision)\n# recall: tp / (tp + fn)\nrecall = recall_score(y_real, y_pred,average='macro')\nprint('Recall: %f' % recall)\n# f1: 2 tp / (2 tp + fp + fn)\nf1 = f1_score(y_real, y_pred,average='macro')\nprint('F1 score: %f' % f1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}